version: "3.2"

services:

  postgres:
    container_name: postgres
    image: postgres
    command:
      - postgres
      - -c
      - 'max_connections=500'
      - -c
      - 'shared_buffers=512MB'
      - -c
      - 'effective_cache_size=1536MB'
      - -c
      - 'maintenance_work_mem=256MB'
      - -c
      - 'checkpoint_completion_target=0.9'
      - -c
      - 'wal_buffers=16MB'
      - -c
      - 'default_statistics_target=100'
      - -c
      - 'random_page_cost=1.1'
      - -c
      - 'effective_io_concurrency=200'
      - -c
      - 'work_mem=131kB'
      - -c
      - 'min_wal_size=1GB'
      - -c
      - 'max_wal_size=4GB'
      - -c
      - 'max_worker_processes=16'
      - -c
      - 'max_parallel_workers_per_gather=4'
      - -c
      - 'max_parallel_workers=16'
      - -c
      - 'max_parallel_maintenance_workers=4'
#      - -c
#      - 'log_statement=all'
#      - -c
#      - 'log_destination=stderr'
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgres
    environment:
      POSTGRES_PASSWORD: password

  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:management
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    volumes:
      - "zookeeper_data:/bitnami"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.0.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    volumes:
      - "kafka_data:/bitnami"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # This "container" is a workaround to pre-create topics
  kafka-setup:
    image: confluentinc/cp-kafka:7.0.0
    hostname: kafka-setup
    container_name: kafka-setup
    depends_on:
      - kafka
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:9092 1 20 && \
                       kafka-topics --create --if-not-exists --bootstrap-server kafka:9092 --partitions ${PARTITION_COUNT} --replication-factor 1 --topic engineEvents'"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored

  query-init:
    image: activiti/activiti-cloud-query:${VERSION}
    container_name: query-init
    command:
      - -jar
      - liquibase.jar
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/postgres
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: password
      SPRING_LIQUIBASE_ENABLED: "true"
    depends_on:
      - postgres

  query-0:
    image: activiti/activiti-cloud-query:${VERSION}
    container_name: query-0
    ports:
      - "5005:5005"
    volumes:
      - apm-agent:/mnt/apm-agent:ro
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/postgres
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: password
      SPRING_LIQUIBASE_ENABLED: "false"
      ACTIVITI_KEYCLOAK_CLIENT_SECRET: dummysecret
      SERVER_PORT: 8080
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_DATASOURCE_HIKARI_MINIMUMIDLE: ${HIKARI_POOL_SIZE}
      SPRING_DATASOURCE_HIKARI_MAXLIFETIME: 1000
      SPRING_DATASOURCE_HIKARI_MAXIMUMPOOLSIZE: ${HIKARI_POOL_SIZE}
      SPRING_DATASOURCE_HIKARI_CONNECTIONTIMEOUT: 10000
      SPRING_DATASOURCE_HIKARI_AUTOCOMMIT: "true"
      JAVA_TOOL_OPTIONS: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005
      JAVA_OPTS: |
        -Dactiviti.cloud.messaging.broker=${BROKER}
        -Dspring.cloud.stream.kafka.binder.brokers=kafka
        -Dspring.cloud.stream.kafka.binder.configuration.partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor
        -Dactiviti.cloud.messaging.partitioned=true
        -Dactiviti.cloud.messaging.partition-count=${PARTITION_COUNT}
        -Dactiviti.cloud.messaging.instance-index=0
        -Dspring.cloud.stream.bindings.applicationMetrics.destination=metrics
        -Dspring.cloud.stream.metrics.properties=spring.cloud.dataflow**,spring.cloud.application**,spring.application**
        -Dspring.cloud.stream.metrics.scheduleInterval=1s
        -Dspring.cloud.application.guid=8009cdc3-eae5-41f0-9ee1-773965f00cb6
        -Dspring.cloud.dataflow.stream.app.label=default-app
        -Dspring.cloud.dataflow.stream.name=query
        -Dspring.application.index=0
        -javaagent:/mnt/apm-agent/elastic-apm-agent-${ELASTIC_APM_AGENT_VERSION}.jar
        -Djava.security.egd=file:/dev/./urandom
        -Delastic.apm.enabled=${ELASTIC_APM_ENABLED}
        -Delastic.apm.service_name=query-0
        -Delastic.apm.server_urls=http://apm-server:8200
        -Delastic.apm.log_level=INFO
        -Delastic.apm.secret_token=${ELASTIC_APM_SERVICE_SECRET_TOKEN}
        -Delastic.apm.environment=${APM_ENVIRONMENT}
        -Delastic.apm.application_packages=org.activiti.cloud
        -Delastic.apm.profiling_inferred_spans_enabled=true
        -Delastic.apm.profiling_inferred_spans_sampling_interval=${SAMPLING_INTERVAL}
        -Delastic.apm.transaction_sample_rate=${SAMPLE_RATE}
        -Ddatasource-proxy.enabled=${DEBUG_SQL}
    depends_on:
      - apm-agent-download
      - query-init

#  query-1:
#    image: activiti/activiti-cloud-query:${VERSION}
#    container_name: query-1
#    #    ports:
#    #      - "8080:8080"
#    #      - "5005:5005"
#    volumes:
#      - apm-agent:/mnt/apm-agent:ro
#    environment:
#      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/postgres
#      SPRING_DATASOURCE_USERNAME: postgres
#      SPRING_DATASOURCE_PASSWORD: password
#      SPRING_LIQUIBASE_ENABLED: "false"
#      ACTIVITI_KEYCLOAK_CLIENT_SECRET: dummysecret
#      SERVER_PORT: 8080
#      SPRING_RABBITMQ_HOST: rabbitmq
#      SPRING_DATASOURCE_HIKARI_MINIMUMIDLE: ${HIKARI_POOL_SIZE}
#      SPRING_DATASOURCE_HIKARI_MAXLIFETIME: 1000
#      SPRING_DATASOURCE_HIKARI_MAXIMUMPOOLSIZE: ${HIKARI_POOL_SIZE}
#      SPRING_DATASOURCE_HIKARI_CONNECTIONTIMEOUT: 10000
#      SPRING_DATASOURCE_HIKARI_AUTOCOMMIT: "true"
#      #      ELASTIC_APM_TRACE_METHODS: "public @org.springframework.cloud.stream.annotation.StreamListener org.activiti.cloud.services.*"
#      #      JAVA_TOOL_OPTIONS: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005 -Ddatasource-proxy.enabled=true
#      JAVA_OPTS: |
#        -Dactiviti.cloud.messaging.broker=${BROKER}
#        -Dspring.cloud.stream.kafka.binder.brokers=kafka
#        -Dspring.cloud.stream.kafka.binder.configuration.partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor
#        -Dactiviti.cloud.messaging.partitioned=true
#        -Dactiviti.cloud.messaging.partition-count=${PARTITION_COUNT}
#        -Dactiviti.cloud.messaging.instance-index=1
#        -Dspring.cloud.stream.bindings.applicationMetrics.destination=metrics
#        -Dspring.cloud.stream.metrics.properties=spring.cloud.dataflow**,spring.cloud.application**,spring.application**
#        -Dspring.cloud.application.guid=8009cdc3-eae5-41f0-9ee1-773965f00cb6
#        -Dspring.cloud.dataflow.stream.app.label=default-app
#        -Dspring.cloud.dataflow.stream.name=query
#        -Dspring.application.index=1
#        -javaagent:/mnt/apm-agent/elastic-apm-agent-${ELASTIC_APM_AGENT_VERSION}.jar
#        -Djava.security.egd=file:/dev/./urandom
#        -Delastic.apm.enabled=${ELASTIC_APM_ENABLED}
#        -Delastic.apm.service_name=query-1
#        -Delastic.apm.server_urls=http://apm-server:8200
#        -Delastic.apm.log_level=INFO
#        -Delastic.apm.secret_token=${ELASTIC_APM_SERVICE_SECRET_TOKEN}
#        -Delastic.apm.environment=${APM_ENVIRONMENT}
#        -Delastic.apm.application_packages=org.activiti.cloud
#        -Delastic.apm.profiling_inferred_spans_enabled=true
#        -Delastic.apm.profiling_inferred_spans_sampling_interval=${SAMPLING_INTERVAL}
#        -Delastic.apm.transaction_sample_rate=${SAMPLE_RATE}
#        -Ddatasource-proxy.enabled=${DEBUG_SQL}
#    depends_on:
#      - apm-agent-download
#      - query-init
#
#  query-2:
#    image: activiti/activiti-cloud-query:${VERSION}
#    container_name: query-2
#    #    ports:
#    #      - "8080:8080"
#    #      - "5005:5005"
#    volumes:
#      - apm-agent:/mnt/apm-agent:ro
#    environment:
#      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/postgres
#      SPRING_DATASOURCE_USERNAME: postgres
#      SPRING_DATASOURCE_PASSWORD: password
#      SPRING_LIQUIBASE_ENABLED: "false"
#      ACTIVITI_KEYCLOAK_CLIENT_SECRET: dummysecret
#      SERVER_PORT: 8080
#      SPRING_RABBITMQ_HOST: rabbitmq
#      SPRING_DATASOURCE_HIKARI_MINIMUMIDLE: ${HIKARI_POOL_SIZE}
#      SPRING_DATASOURCE_HIKARI_MAXLIFETIME: 1000
#      SPRING_DATASOURCE_HIKARI_MAXIMUMPOOLSIZE: ${HIKARI_POOL_SIZE}
#      SPRING_DATASOURCE_HIKARI_CONNECTIONTIMEOUT: 10000
#      SPRING_DATASOURCE_HIKARI_AUTOCOMMIT: "true"
#      #      ELASTIC_APM_TRACE_METHODS: "public @org.springframework.cloud.stream.annotation.StreamListener org.activiti.cloud.services.*"
#      #      JAVA_TOOL_OPTIONS: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005
#      JAVA_OPTS: |
#        -Dactiviti.cloud.messaging.broker=${BROKER}
#        -Dspring.cloud.stream.kafka.binder.brokers=kafka
#        -Dspring.cloud.stream.kafka.binder.configuration.partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor
#        -Dactiviti.cloud.messaging.partitioned=true
#        -Dactiviti.cloud.messaging.partition-count=${PARTITION_COUNT}
#        -Dactiviti.cloud.messaging.instance-index=2
#        -Dspring.cloud.stream.bindings.applicationMetrics.destination=metrics
#        -Dspring.cloud.stream.metrics.properties=spring.cloud.dataflow**,spring.cloud.application**,spring.application**
#        -Dspring.cloud.application.guid=8009cdc3-eae5-41f0-9ee1-773965f00cb6
#        -Dspring.cloud.dataflow.stream.app.label=default-app
#        -Dspring.cloud.dataflow.stream.name=query
#        -Dspring.application.index=2
#        -javaagent:/mnt/apm-agent/elastic-apm-agent-${ELASTIC_APM_AGENT_VERSION}.jar
#        -Djava.security.egd=file:/dev/./urandom
#        -Delastic.apm.enabled=${ELASTIC_APM_ENABLED}
#        -Delastic.apm.service_name=query-2
#        -Delastic.apm.server_urls=http://apm-server:8200
#        -Delastic.apm.log_level=INFO
#        -Delastic.apm.secret_token=${ELASTIC_APM_SERVICE_SECRET_TOKEN}
#        -Delastic.apm.environment=${APM_ENVIRONMENT}
#        -Delastic.apm.application_packages=org.activiti.cloud
#        -Delastic.apm.profiling_inferred_spans_enabled=true
#        -Delastic.apm.profiling_inferred_spans_sampling_interval=${SAMPLING_INTERVAL}
#        -Delastic.apm.transaction_sample_rate=${SAMPLE_RATE}
#        -Ddatasource-proxy.enabled=${DEBUG_SQL}
#    depends_on:
#      - apm-agent-download
#      - query-init

#  query-3:
#    image: activiti/activiti-cloud-query:${VERSION}
#    container_name: query-3
#    #    ports:
#    #      - "8080:8080"
#    #      - "5005:5005"
#    volumes:
#      - apm-agent:/mnt/apm-agent:ro
#    environment:
#      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/postgres #?reWriteBatchedInserts=true
#      #      SPRING_DATASOURCE_URL: jdbc:postgresql://pgbouncer:6432/postgres?prepareThreshold=0
#      SPRING_DATASOURCE_USERNAME: postgres
#      SPRING_DATASOURCE_PASSWORD: password
#      ACTIVITI_KEYCLOAK_CLIENT_SECRET: dummysecret
#      SERVER_PORT: 8080
#      SPRING_RABBITMQ_HOST: rabbitmq
#      SPRING_DATASOURCE_HIKARI_MINIMUMIDLE: 10
#      SPRING_DATASOURCE_HIKARI_MAXLIFETIME: 1000
#      SPRING_DATASOURCE_HIKARI_MAXIMUMPOOLSIZE: 10
#      SPRING_DATASOURCE_HIKARI_CONNECTIONTIMEOUT: 10000
#      SPRING_DATASOURCE_HIKARI_AUTOCOMMIT: "true"
#      #      ELASTIC_APM_TRACE_METHODS: "public @org.springframework.cloud.stream.annotation.StreamListener org.activiti.cloud.services.*"
#      #      JAVA_TOOL_OPTIONS: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005 -Ddatasource-proxy.enabled=true
#      JAVA_OPTS: |
#        -Dactiviti.cloud.messaging.broker=${BROKER} -Dspring.cloud.stream.kafka.binder.brokers=kafka
#        -Dactiviti.cloud.messaging.partitioned=true
#        -Dactiviti.cloud.messaging.partition-count=${PARTITION_COUNT}
#        -Dactiviti.cloud.messaging.instance-index=3
#        -Dspring.cloud.stream.bindings.applicationMetrics.destination=metrics
#        -Dspring.cloud.stream.metrics.properties=spring.cloud.dataflow**,spring.cloud.application**,spring.application**
#        -Dspring.cloud.application.guid=8009cdc3-eae5-41f0-9ee1-773965f00cb6
#        -Dspring.cloud.dataflow.stream.app.label=default-app
#        -Dspring.cloud.dataflow.stream.name=query
#        -Dspring.application.index=3
#        -javaagent:/mnt/apm-agent/elastic-apm-agent-${ELASTIC_APM_AGENT_VERSION}.jar
#        -Djava.security.egd=file:/dev/./urandom
#        -Delastic.apm.enabled=${ELASTIC_APM_ENABLED}
#        -Delastic.apm.service_name=query-3
#        -Delastic.apm.server_urls=http://apm-server:8200
#        -Delastic.apm.log_level=INFO
#        -Delastic.apm.secret_token=${ELASTIC_APM_SERVICE_SECRET_TOKEN}
#        -Delastic.apm.environment=${APM_ENVIRONMENT}
#        -Delastic.apm.application_packages=org.activiti.cloud
#        -Delastic.apm.profiling_inferred_spans_enabled=true
#        -Delastic.apm.profiling_inferred_spans_sampling_interval=${SAMPLING_INTERVAL}
#        -Delastic.apm.transaction_sample_rate=${SAMPLE_RATE}
#        -Ddatasource-proxy.enabled=${DEBUG_SQL}
#    depends_on:
#      - apm-agent-download

#  metrics-collector:
#    image: metrics-collector-kafka
#    container_name: metrics-collector
#    ports:
#      - "9080:8080"
#    volumes:
#      - apm-agent:/mnt/apm-agent:ro
#    environment:
#      SPRING_RABBITMQ_HOST: rabbitmq
#      JAVA_TOOL_OPTIONS: |
#        -Dspring.cloud.stream.kafka.binder.brokers=kafka
#        -javaagent:/mnt/apm-agent/elastic-apm-agent-${ELASTIC_APM_AGENT_VERSION}.jar
#        -Delastic.apm.enabled=${ELASTIC_APM_ENABLED}
#        -Delastic.apm.service_name=metrics-collector
#        -Delastic.apm.server_urls=http://apm-server:8200
#        -Delastic.apm.log_level=INFO
#        -Delastic.apm.secret_token=${ELASTIC_APM_SERVICE_SECRET_TOKEN}
#        -Delastic.apm.environment=${APM_ENVIRONMENT}
#        -Delastic.apm.application_packages=org.springframework.cloud.dataflow

  apm-agent-download:
    image: alpine:latest
    container_name: apm-agent-download
    command: sh -c 'cd /root/apm-agent ; wget https://repo1.maven.org/maven2/co/elastic/apm/elastic-apm-agent/${ELASTIC_APM_AGENT_VERSION}/elastic-apm-agent-${ELASTIC_APM_AGENT_VERSION}.jar'
    volumes:
      - apm-agent:/root/apm-agent

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION}
    environment:
      - xpack.security.enabled=false
      - bootstrap.memory_lock=true
      - cluster.name=docker-cluster
      - cluster.routing.allocation.disk.threshold_enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g
    ports:
      - "9200:9200"
    ulimits:
      memlock:
        hard: -1
        soft: -1
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:${ELASTIC_VERSION}
    environment:
      - "SERVER_HOST=0.0.0.0"
      - "ELASTICSEARCH_URL=http://elasticsearch:9200"
      - "ELASTICSEARCH_HOSTS=http://elasticsearch:9200"
    ports:
      - "5601:5601"
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status
    depends_on:
      - elasticsearch

  apm-server:
    container_name: apm-server
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    image: docker.elastic.co/apm/apm-server:${ELASTIC_VERSION}
    ports:
      - "8200:8200"
    environment:
      - output.elasticsearch.hosts=['http://elasticsearch:9200']
      - apm-server.host="0.0.0.0:8200"
      - apm-server.secret_token=${ELASTIC_APM_SERVICE_SECRET_TOKEN}
      - apm-server.kibana.enabled=true
      - apm-server.kibana.host=kibana:5601
      - logging.to_files=false
      - apm-server.rum.enabled=true
      - setup.template.settings.index.number_of_replicas=0
      - output.elasticsearch.bulk_max_size=5120
      - output.elasticsearch.worker=3
      - queue.mem.events=15360
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/
    depends_on:
      - elasticsearch
      - kibana

volumes:
  postgres_data: {}
  rabbitmq_data: {}
  apm-agent: {}
  es_data: {}
  kafka_data: {}
  zookeeper_data: {}
